{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "from collections import Counter\n",
    "from indicnlp.tokenize import indic_tokenize\n",
    "import re\n",
    "\n",
    "# Load and preprocess Malayalam text from a text file\n",
    "def load_data_from_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()  # Read lines from the text file\n",
    "    corpus = \"\"\n",
    "    for line in lines:\n",
    "        line = line.strip()  # Remove leading/trailing whitespaces\n",
    "        if line:  # Ignore empty lines\n",
    "            corpus += line + \" \"\n",
    "    \n",
    "    # Preprocessing: Remove non-Malayalam characters and tokenize\n",
    "    corpus = re.sub(r'[^\\u0D00-\\u0D7F\\s]', '', corpus).lower()  # Keep Malayalam chars only\n",
    "    tokens = list(indic_tokenize.trivial_tokenize(corpus, lang='ml'))\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# Build n-gram model from tokenized text\n",
    "tokens_ml = load_data_from_file('Dataset/train.txt')\n",
    "\n",
    "# Create bigrams and trigrams\n",
    "bigrams_ml = list(ngrams(tokens_ml, 2))\n",
    "trigrams_ml = list(ngrams(tokens_ml, 3))\n",
    "\n",
    "# Frequency counts for bigrams and trigrams\n",
    "bigram_freq_ml = Counter(bigrams_ml)\n",
    "trigram_freq_ml = Counter(trigrams_ml)\n",
    "word_freq_ml = Counter(tokens_ml)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction function using bigrams or trigrams (higher-order n-grams)\n",
    "def predict_next_word_ngram(words, top_n=5):\n",
    "    # print(\"top: \", words)\n",
    "    if len(words) == 1:\n",
    "        # print(\"Bigram model (single word as context)\")\n",
    "        word = words[0]\n",
    "        candidates = [\n",
    "            (w2, bigram_freq_ml[(word, w2)] / word_freq_ml[word]) \n",
    "            for (w1, w2) in bigram_freq_ml if w1 == word\n",
    "        ]\n",
    "        # print(candidates)\n",
    "    elif len(words) >= 2:\n",
    "        # Trigram model (two words as context)\n",
    "        word1, word2 = words[-2], words[-1]\n",
    "        candidates = [\n",
    "            (w3, trigram_freq_ml[(word1, word2, w3)] / bigram_freq_ml[(word1, word2)])\n",
    "            for (w1, w2, w3) in trigram_freq_ml if w1 == word1 and w2 == word2\n",
    "        ]\n",
    "        if (len(candidates) == 0) and (isinstance(words,list)) :\n",
    "            # print(type(words))\n",
    "            # print(words)\n",
    "            words.pop(0)\n",
    "            return predict_next_word_ngram(words)\n",
    "    else:\n",
    "        return {\"error\": \"Insufficient words for prediction\"}\n",
    "    \n",
    "    # Sort candidates by probability\n",
    "    # print(\"c1: \", candidates)\n",
    "    candidates = sorted(candidates, key=lambda x: x[1], reverse=True)\n",
    "    return candidates[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('വില്ലൻ', 0.09947643979057591), ('പുറത്തിറക്കിയിട്ടുണ്ട്', 0.020942408376963352), ('പ്രസിദ്ധീകരിച്ചത്', 0.020942408376963352), ('ലത്തീനിലുള്ളതിനുള്ളതിനോട്', 0.020942408376963352), ('എന്ന', 0.020942408376963352)]\n"
     ]
    }
   ],
   "source": [
    "words = \"അവൾ പുസ്തകം\"\n",
    "word_list = words.split()\n",
    "if len(predict_next_word_ngram(word_list)) == 0:\n",
    "    print(\"no word\")\n",
    "else:\n",
    "    print(predict_next_word_ngram(word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "w= [\"1\",\"2\"]\n",
    "w.pop(0)\n",
    "w\n",
    "if type(w) == str:\n",
    "    print(1)\n",
    "else:\n",
    "    print(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['അവൻ', 'സ്കൂളിലേക്ക്', 'പോയി']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from indicnlp.tokenize import indic_tokenize\n",
    "import re\n",
    "\n",
    "# Example Malayalam text\n",
    "text_ml = \"അവൻ സ്കൂളിലേക്ക് പോയി.\"\n",
    "\n",
    "# Preprocess: Lowercasing and punctuation removal\n",
    "text_ml = re.sub(r'[^\\u0D00-\\u0D7F\\s]', '', text_ml)  # Keep Malayalam chars only\n",
    "\n",
    "# Tokenize\n",
    "tokens_ml = list(indic_tokenize.trivial_tokenize(text_ml, lang='ml'))\n",
    "print(tokens_ml)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_word_ml(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
